# Inference / 推理

This directory contains notes and resources related to AI model inference.

## Topics to Cover

- Inference optimisation techniques
- Model deployment strategies
- Serving frameworks
- Quantisation and compression
- Edge deployment
- Batch vs real-time inference
- Performance monitoring

## 主题内容

- 推理优化技术
- 模型部署策略
- 服务框架
- 量化和压缩
- 边缘部署
- 批量推理与实时推理
- 性能监控
